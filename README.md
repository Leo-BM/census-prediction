# üìä Classifica√ß√£o de Renda - Censo Americano

> *Um estudo pr√°tico sobre Algoritmos de Classifica√ß√£o (√Årvores de Decis√£o e Random Forest) aplicados a dados demogr√°ficos.*

##  Sobre Mim e o Projeto
Ol√°! Sou um desenvolvedor Front-end em transi√ß√£o de carreira para a √°rea de **Data Science e Machine Learning**. 

Este reposit√≥rio documenta meus estudos iniciais com algoritmos de classifica√ß√£o supervisionada. O objetivo deste projeto n√£o √© apenas obter a maior acur√°cia poss√≠vel, mas sim consolidar os fundamentos de pr√©-processamento de dados, an√°lise explorat√≥ria e a diferen√ßa pr√°tica entre modelos de √°rvore √∫nica e florestas de decis√£o.

##  O Dataset
Utilizei a base de dados cl√°ssica **"Census Income"** (tamb√©m conhecida como *Adult Data Set*).
* **Fonte:**  https://archive.ics.uci.edu/dataset/20/census+income   -> Extra√≠da do censo de 1994 dos EUA.
* **Objetivo:** Prever se a renda anual de uma pessoa excede **$50.000 (<=50K ou >50K)**.
* **Atributos:** Idade, classe de trabalho, educa√ß√£o, estado civil, ocupa√ß√£o, relacionamento, ra√ßa, sexo, horas trabalhadas por semana, pa√≠s nativo, etc.

##  Tecnologias Utilizadas
* **Linguagem:** Python
* **Manipula√ß√£o de Dados:** Pandas, NumPy
* **Visualiza√ß√£o:** Matplotlib, Seaborn
* **Machine Learning:** Scikit-Learn (Decision Tree, Random Forest)
* **Ferramenta:** Google Colab / Jupyter Notebook

##  Etapas do Projeto

### 1. An√°lise Explorat√≥ria de Dados (EDA)
Realizei uma an√°lise visual para entender a distribui√ß√£o dos dados, identificando padr√µes como:
* Distribui√ß√£o de idade e horas de trabalho.
* Desbalanceamento das classes (h√° muito mais pessoas ganhando <=50K do que >50K).
* Visualiza√ß√£o de *Outliers* atrav√©s de Boxplots.

### 2. Pr√©-processamento
Esta foi a etapa mais cr√≠tica do aprendizado. Tratei os dados brutos para que pudessem ser lidos pelos algoritmos:
* **Tratamento de dados faltantes.**
* **Separa√ß√£o de vari√°veis:** Divis√£o entre previsores (X) e classe (y).
* **Encoding:** Transforma√ß√£o de vari√°veis categ√≥ricas (texto) em num√©ricas. Estudei o uso de `LabelEncoder` e as vantagens do `OneHotEncoder` via `ColumnTransformer`.
* **Escalonamento:** Padroniza√ß√£o de escalas (StandardScaler) para vari√°veis num√©ricas (embora √°rvores sofram menos com isso, √© uma boa pr√°tica).
* **Divis√£o Treino/Teste:** Separa√ß√£o cl√°ssica para validar o modelo.

### 3. Modelagem e Comparativo
Treinei e comparei dois algoritmos populares:

| Modelo | Acur√°cia (Teste) | Observa√ß√µes |
| :--- | :--- | :--- |
| **√Årvore de Decis√£o** (Decision Tree) | *~81.0%* | Modelo mais simples, r√°pido, por√©m tende a sofrer overfitting facilmente se n√£o podado. |
| **Random Forest** (Floresta Aleat√≥ria) | *~85.0%* | Modelo de *Ensemble*. Mais robusto e est√°vel, pois combina o voto de m√∫ltiplas √°rvores (neste teste, usamos 40 √°rvores). |

> *Nota: Os valores de acur√°cia podem variar ligeiramente dependendo da semente aleat√≥ria (random_state) utilizada na separa√ß√£o dos dados.*

## üöÄ Pr√≥ximos Passos (Melhorias Futuras)
Como parte do meu aprendizado cont√≠nuo, pretendo revisitar este projeto para aplicar:
- [ ] **Cross-Validation (Valida√ß√£o Cruzada)** para ter uma m√©trica de acur√°cia mais confi√°vel.
- [ ] **GridSearchCV** para encontrar os melhores par√¢metros automaticamente (tuning).
- [ ] Testar algoritmos mais avan√ßados como **XGBoost** ou **LightGBM**.
- [ ] Melhorar o tratamento do desbalanceamento de classes (SMOTE).

##  Contato
Se voc√™ tiver dicas ou sugest√µes de melhoria para o c√≥digo, sinta-se √† vontade para abrir uma *issue* ou entrar em contato! Estou sempre aberto a aprender.

---
*Desenvolvido por Leonardo Bento Maria durante estudos de Machine Learning.*
